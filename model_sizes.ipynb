{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24385b2c-d04b-4e68-9635-d3558b7128ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from transformers import ( \n",
    "        Trainer,\n",
    "        AutoModelForSequenceClassification,\n",
    "        AutoConfig)\n",
    "import objsize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "088fcd5c-974e-4289-8092-a333d75ae3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model import load_models\n",
    "from utils.quantizer import quantize_model, norm_quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d77fc57b-fc1d-4f23-bf48-a2816cf21917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_memory(model_loaded, n_bits_base):\n",
    "    total_params = sum(p.count_nonzero() for p in model_loaded.parameters())\n",
    "    n_bits = 32\n",
    "    return total_params* (n_bits/8)*1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4f735ecf-9534-4b1f-b2e5-2a05a77a71ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-quantized memory: 437.94\n",
      "Quantized memory: 348.83 MB\n",
      "Non-quantized memory: 437.94\n",
      "Quantized memory: 348.80 MB\n",
      "Non-quantized memory: 437.94\n",
      "Quantized memory: 348.83 MB\n",
      "Non-quantized memory: 437.93\n",
      "Quantized memory: 348.83 MB\n",
      "Non-quantized memory: 437.94\n",
      "Quantized memory: 348.96 MB\n",
      "Non-quantized memory: 437.94\n",
      "Quantized memory: 348.95 MB\n",
      "Non-quantized memory: 437.94\n",
      "Quantized memory: 348.86 MB\n",
      "Non-quantized memory: 437.94\n",
      "Quantized memory: 348.82 MB\n",
      "Non-quantized memory: 437.94\n",
      "Quantized memory: 348.82 MB\n"
     ]
    }
   ],
   "source": [
    "task_to_keys = {\n",
    "    'cola': ('sentence', None),\n",
    "    'mnli': ('premise', 'hypothesis'),\n",
    "    'mrpc': ('sentence1', 'sentence2'),\n",
    "    'qnli': ('question', 'sentence'),\n",
    "    'qqp': ('question1', 'question2'),\n",
    "    'rte': ('sentence1', 'sentence2'),\n",
    "    'sst2': ('sentence', None),\n",
    "    'stsb': ('sentence1', 'sentence2'),\n",
    "    'wnli': ('sentence1', 'sentence2')}\n",
    "\n",
    "\n",
    "ms = [\n",
    "'JeremiahZ/bert-base-uncased-cola',\n",
    "'doyoungkim/bert-base-uncased-finetuned-sst2',\n",
    "'Intel/bert-base-uncased-mrpc',\n",
    "'JeremiahZ/bert-base-uncased-stsb',\n",
    "'JeremiahZ/bert-base-uncased-qqp',\n",
    "'JeremiahZ/bert-base-uncased-mnli',\n",
    "'JeremiahZ/bert-base-uncased-qnli',\n",
    "'JeremiahZ/bert-base-uncased-rte',\n",
    "'JeremiahZ/bert-base-uncased-wnli']\n",
    "for m in ms:\n",
    "    model_loaded = AutoModelForSequenceClassification.from_pretrained(m)\n",
    "    print(\"Non-quantized memory: {:.2f}\".format(count_memory(model_loaded, n_bits_base)))\n",
    "    model_quantized = quantize_model(model_loaded, lambda X: norm_quantize(X, 0.01))\n",
    "    n_bits_base = 32\n",
    "    print(\"Quantized memory: {:.2f} MB\".format(count_memory(model_quantized, n_bits_base)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad0270-0496-4e1c-a3f3-7e1ec814fdd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
